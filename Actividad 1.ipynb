{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i> Alejandro Tolosa\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Lectura y análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Abrir entorno de programación, de preferencia utilizar Visual Studio Code, Google Colabg o Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Importe (e instale en caso de ser necesario) librería Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Cargar la base de datos de nombre \"ejemplo data.csv\". En esta parte recomendamos explorar las diferentes opciones de read que tiene disponible la librería Pandas, identificando los argumentos disponibles en cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ejemplo_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Identifique los tipos de variables que hay disponibles en la base de datos (df.types o df.info())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID              int64\n",
      "Nombre         object\n",
      "2016           object\n",
      "2017           object\n",
      "Crecimiento    object\n",
      "Unidades       object\n",
      "fecha          object\n",
      "Activo          int64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           5 non-null      int64 \n",
      " 1   Nombre       5 non-null      object\n",
      " 2   2016         5 non-null      object\n",
      " 3   2017         5 non-null      object\n",
      " 4   Crecimiento  5 non-null      object\n",
      " 5   Unidades     5 non-null      object\n",
      " 6   fecha        5 non-null      object\n",
      " 7   Activo       5 non-null      int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 452.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Utilizando la función astype transforme el atributo ”ID” a entero y el atributo ”Activo” a booleano. Vuelva a consultar el estado de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID              int32\n",
      "Nombre         object\n",
      "2016           object\n",
      "2017           object\n",
      "Crecimiento    object\n",
      "Unidades       object\n",
      "fecha          object\n",
      "Activo           bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['ID'] = df['ID'].astype(int)\n",
    "df['Activo'] = df['Activo'].astype(bool)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Convierta el atributo ”unidades” a entero y ”2016” a flotante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID               int32\n",
      "Nombre          object\n",
      "2016           float64\n",
      "2017            object\n",
      "Crecimiento     object\n",
      "Unidades         int32\n",
      "fecha           object\n",
      "Activo            bool\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_21804\\3941008958.py:4: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df['2016'] = df['2016'].replace('[\\$,]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "df['Unidades'] = df['Unidades'].replace('No', 0)\n",
    "df['Unidades'] = df['Unidades'].astype(int)\n",
    "\n",
    "df['2016'] = df['2016'].replace('[\\$,]', '', regex=True)\n",
    "df['2016'] = df['2016'].astype(float)\n",
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lectura y análisis exploratorio de datos 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Cargar la base de datos de nombre ”ecommerce data.csv”. En esta parte recomendamos explorar las diferentes opciones de read que tiene disponible la librería Pandas, identificando los argumentos disponibles en cada una de ellas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'UnitPrice', 'CustomerID', 'Country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_ecommerce = pd.read_csv('ecommerce_data.csv', encoding='latin1')\n",
    "print(df_ecommerce.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Identifique los tipos de varibles que hay disponibles en la base de datos (df.types o df.info()). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo       object\n",
      "StockCode       object\n",
      "Description     object\n",
      "Quantity         int64\n",
      "InvoiceDate     object\n",
      "UnitPrice      float64\n",
      "CustomerID     float64\n",
      "Country         object\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_ecommerce.dtypes)\n",
    "print(df_ecommerce.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Utilizando la función astype transforme el atributo ”InvoiceNo” a entero y el atributo ”Description” a string. Vuelva a consultar el estado de las variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0     536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1     536365     71053                  WHITE METAL LANTERN         6   \n",
      "2     536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3     536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4     536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "df_ecommerce = df_ecommerce[df_ecommerce['InvoiceNo'].str.isdigit()]\n",
    "df_ecommerce['InvoiceNo'] = df_ecommerce['InvoiceNo'].astype(int)\n",
    "\n",
    "df_ecommerce['Description'] = df_ecommerce['Description'].astype(str)\n",
    "\n",
    "print(df_ecommerce.head())\n",
    "\n",
    "df_ecommerce.to_csv('processed_ecommerce_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Convierta el atributo ”Quantity” a entero y ”UnitPrice” a flotante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo        int32\n",
      "StockCode       object\n",
      "Description     object\n",
      "Quantity         int32\n",
      "InvoiceDate     object\n",
      "UnitPrice      float64\n",
      "CustomerID     float64\n",
      "Country         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_ecommerce['Quantity'] = df_ecommerce['Quantity'].astype(int)\n",
    "df_ecommerce['UnitPrice'] = df_ecommerce['UnitPrice'].astype(float)\n",
    "print(df_ecommerce.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• La columna ”InvoiceDate” contiene un string que representa ”fecha-hora”, separe la columna en dos columnas que representen cada atributo por separado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecommerce[['fecha', 'hora']] = df_ecommerce['InvoiceDate'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Añada una nueva columna que represente el monto total para cada boleta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecommerce['TotalAmount'] = df_ecommerce['Quantity'] * df_ecommerce['UnitPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Exporte la base de datos procesada en formato ”.csv” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecommerce.to_csv('processed_ecommerce_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Exploración de funciones groupby, sort values, set index, sample, pivot, reset index y merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo        int32\n",
      "StockCode       object\n",
      "Description     object\n",
      "Quantity         int32\n",
      "InvoiceDate     object\n",
      "UnitPrice      float64\n",
      "CustomerID     float64\n",
      "Country         object\n",
      "fecha           object\n",
      "hora            object\n",
      "TotalAmount    float64\n",
      "dtype: object\n",
      "   InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0     536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1     536365     71053                  WHITE METAL LANTERN         6   \n",
      "2     536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3     536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4     536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "      InvoiceDate  UnitPrice  CustomerID         Country      fecha  hora  \\\n",
      "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  12/1/2010  8:26   \n",
      "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  12/1/2010  8:26   \n",
      "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  12/1/2010  8:26   \n",
      "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  12/1/2010  8:26   \n",
      "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  12/1/2010  8:26   \n",
      "\n",
      "   TotalAmount  \n",
      "0        15.30  \n",
      "1        20.34  \n",
      "2        22.00  \n",
      "3        20.34  \n",
      "4        20.34  \n"
     ]
    }
   ],
   "source": [
    "df_ecommerce['Quantity'] = df_ecommerce['Quantity'].astype(int)\n",
    "df_ecommerce['UnitPrice'] = df_ecommerce['UnitPrice'].astype(float)\n",
    "print(df_ecommerce.dtypes)\n",
    "\n",
    "df_ecommerce[['fecha', 'hora']] = df_ecommerce['InvoiceDate'].str.split(' ', expand=True)\n",
    "\n",
    "df_ecommerce['TotalAmount'] = df_ecommerce['Quantity'] * df_ecommerce['UnitPrice']\n",
    "print(df_ecommerce.head())\n",
    "df_ecommerce = df_ecommerce.drop_duplicates(subset=['InvoiceNo', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby\n",
    "df_grouped = df_ecommerce.groupby('Description').sum()\n",
    "\n",
    "# sort_values\n",
    "df_sorted = df_ecommerce.sort_values(by='TotalAmount', ascending=False)\n",
    "\n",
    "# set_index\n",
    "df_indexed = df_ecommerce.set_index('InvoiceNo')\n",
    "\n",
    "# sample\n",
    "df_sample = df_ecommerce.sample(n=10)\n",
    "\n",
    "# pivot\n",
    "df_pivot = df_ecommerce.pivot(index='InvoiceNo', columns='Description', values='TotalAmount')\n",
    "\n",
    "# reset_index\n",
    "df_reset = df_ecommerce.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Estadísticas descriptivas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Crear un diccionario con 50 datos que contenga al menos tres atributos continuos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Atributo1': np.random.rand(50),\n",
    "    'Atributo2': np.random.rand(50),\n",
    "    'Atributo3': np.random.rand(50)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Transforme dicho diccionario a un dataFrame de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Obtenga estadísticas descriptivas de tendencia central. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributo1    0.434782\n",
      "Atributo2    0.491093\n",
      "Atributo3    0.521991\n",
      "dtype: float64\n",
      "Atributo1    0.396414\n",
      "Atributo2    0.531566\n",
      "Atributo3    0.523497\n",
      "dtype: float64\n",
      "    Atributo1  Atributo2  Atributo3\n",
      "0    0.003789   0.010254   0.008320\n",
      "1    0.011616   0.022381   0.042663\n",
      "2    0.026667   0.027638   0.058021\n",
      "3    0.036789   0.032883   0.065705\n",
      "4    0.039989   0.061189   0.099804\n",
      "5    0.054146   0.063878   0.118780\n",
      "6    0.081552   0.067720   0.124813\n",
      "7    0.084079   0.121276   0.125300\n",
      "8    0.103838   0.133016   0.162911\n",
      "9    0.113919   0.142970   0.230355\n",
      "10   0.122609   0.143609   0.252505\n",
      "11   0.128232   0.145499   0.302156\n",
      "12   0.136053   0.149773   0.312470\n",
      "13   0.215165   0.176796   0.319329\n",
      "14   0.254858   0.216577   0.344115\n",
      "15   0.284378   0.231985   0.355659\n",
      "16   0.284567   0.288107   0.369485\n",
      "17   0.299218   0.409899   0.376088\n",
      "18   0.305748   0.419281   0.387622\n",
      "19   0.309537   0.425354   0.425009\n",
      "20   0.311294   0.433385   0.442484\n",
      "21   0.319384   0.439068   0.451865\n",
      "22   0.341812   0.478028   0.453124\n",
      "23   0.345910   0.506472   0.477554\n",
      "24   0.350171   0.531094   0.516823\n",
      "25   0.442656   0.532038   0.530170\n",
      "26   0.445188   0.543530   0.572606\n",
      "27   0.453109   0.554689   0.579229\n",
      "28   0.465635   0.573083   0.607873\n",
      "29   0.470893   0.623826   0.618807\n",
      "30   0.479469   0.627621   0.660683\n",
      "31   0.544938   0.653519   0.691195\n",
      "32   0.555638   0.712260   0.695879\n",
      "33   0.577155   0.721384   0.697062\n",
      "34   0.612543   0.731041   0.699521\n",
      "35   0.681343   0.744787   0.706750\n",
      "36   0.701702   0.745468   0.712861\n",
      "37   0.713728   0.761620   0.771639\n",
      "38   0.717663   0.779121   0.776391\n",
      "39   0.718650   0.799066   0.814111\n",
      "40   0.736984   0.814603   0.842110\n",
      "41   0.776315   0.839353   0.851270\n",
      "42   0.787646   0.855867   0.853581\n",
      "43   0.815652   0.862499   0.873913\n",
      "44   0.845480   0.873210   0.925018\n",
      "45   0.868085   0.876384   0.935549\n",
      "46   0.893356   0.892676   0.949215\n",
      "47   0.918175   0.910599   0.958964\n",
      "48   0.967965   0.910849   0.968357\n",
      "49   0.983832   0.937447   0.983809\n"
     ]
    }
   ],
   "source": [
    "print(df_stats.mean())\n",
    "print(df_stats.median())\n",
    "print(df_stats.mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Obtenga estadísticas descriptivas de dispersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributo1    0.087300\n",
      "Atributo2    0.093738\n",
      "Atributo3    0.084739\n",
      "dtype: float64\n",
      "Atributo1    0.295465\n",
      "Atributo2    0.306167\n",
      "Atributo3    0.291100\n",
      "dtype: float64\n",
      "       Atributo1  Atributo2  Atributo3\n",
      "count  50.000000  50.000000  50.000000\n",
      "mean    0.434782   0.491093   0.521991\n",
      "std     0.295465   0.306167   0.291100\n",
      "min     0.003789   0.010254   0.008320\n",
      "25%     0.155831   0.156529   0.314185\n",
      "50%     0.396414   0.531566   0.523497\n",
      "75%     0.710721   0.757582   0.756945\n",
      "max     0.983832   0.937447   0.983809\n"
     ]
    }
   ],
   "source": [
    "print(df_stats.var())\n",
    "print(df_stats.std())\n",
    "print(df_stats.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Transformación e imputación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Importe la librería sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Cargar las bases de datos de nombre ”ratings data.csv” y ”books data.csv”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  User-ID        ISBN  Book-Rating  MeanRating\n",
      "0           0   276725  034545104X            0    2.933333\n",
      "1           1   276726  0155061224            5    2.500000\n",
      "2           2   276727  0446520802            0    4.060345\n",
      "3           3   276729  052165615X            3    3.000000\n",
      "4           4   276729  0521795028            6    6.000000\n",
      "         ISBN                                         Book-Title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "            Book-Author  Year-Of-Publication                Publisher  \\\n",
      "0    Mark P. O. Morford                 2002  Oxford University Press   \n",
      "1  Richard Bruce Wright                 2001    HarperFlamingo Canada   \n",
      "2          Carlo D'Este                 1991          HarperPerennial   \n",
      "3      Gina Bari Kolata                 1999     Farrar Straus Giroux   \n",
      "4       E. J. W. Barber                 1999   W. W. Norton & Company   \n",
      "\n",
      "                                         Image-URL-S  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-M  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-L  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n",
      "3  http://images.amazon.com/images/P/0374157065.0...  \n",
      "4  http://images.amazon.com/images/P/0393045218.0...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ratings = pd.read_csv('ratings_data.csv')\n",
    "df_books = pd.read_csv('books_data.csv', encoding='latin1', delimiter=';')\n",
    "\n",
    "print(df_ratings.head())\n",
    "print(df_books.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Utilizando ”ratings data.csv” genere un diagnóstico de números perdidos. Luego impute los valores de acuerdo a la media y de acuerdo a otro criterio seleccionado por usted. Explore las opciones de imputación del método fillna() de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores perdidos por columna:\n",
      "Unnamed: 0     0\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "MeanRating     0\n",
      "dtype: int64\n",
      "Valores imputados de acuerdo a la media:\n",
      "   Unnamed: 0  User-ID        ISBN  Book-Rating  MeanRating\n",
      "0           0   276725  034545104X          0.0    2.933333\n",
      "1           1   276726  0155061224          5.0    2.500000\n",
      "2           2   276727  0446520802          0.0    4.060345\n",
      "3           3   276729  052165615X          3.0    3.000000\n",
      "4           4   276729  0521795028          6.0    6.000000\n",
      "Valores imputados con fillna(0):\n",
      "   Unnamed: 0  User-ID        ISBN  Book-Rating  MeanRating\n",
      "0           0   276725  034545104X          0.0    2.933333\n",
      "1           1   276726  0155061224          5.0    2.500000\n",
      "2           2   276727  0446520802          0.0    4.060345\n",
      "3           3   276729  052165615X          3.0    3.000000\n",
      "4           4   276729  0521795028          6.0    6.000000\n",
      "Valores imputados con la media usando fillna():\n",
      "   Unnamed: 0  User-ID        ISBN  Book-Rating  MeanRating\n",
      "0           0   276725  034545104X          0.0    2.933333\n",
      "1           1   276726  0155061224          5.0    2.500000\n",
      "2           2   276727  0446520802          0.0    4.060345\n",
      "3           3   276729  052165615X          3.0    3.000000\n",
      "4           4   276729  0521795028          6.0    6.000000\n",
      "Valores imputados con la mediana usando fillna():\n",
      "   Unnamed: 0  User-ID        ISBN  Book-Rating  MeanRating\n",
      "0           0   276725  034545104X          0.0    2.933333\n",
      "1           1   276726  0155061224          5.0    2.500000\n",
      "2           2   276727  0446520802          0.0    4.060345\n",
      "3           3   276729  052165615X          3.0    3.000000\n",
      "4           4   276729  0521795028          6.0    6.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "missing_values = df_ratings.isnull().sum()\n",
    "print(\"Número de valores perdidos por columna:\")\n",
    "print(missing_values)\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "df_ratings['Book-Rating'] = mean_imputer.fit_transform(df_ratings[['Book-Rating']])\n",
    "print(\"Valores imputados de acuerdo a la media:\")\n",
    "print(df_ratings.head())\n",
    "\n",
    "df_ratings['Book-Rating'] = df_ratings['Book-Rating'].fillna(0)\n",
    "print(\"Valores imputados con fillna(0):\")\n",
    "print(df_ratings.head())\n",
    "\n",
    "mean_value = df_ratings['Book-Rating'].mean()\n",
    "df_ratings['Book-Rating'] = df_ratings['Book-Rating'].fillna(mean_value)\n",
    "print(\"Valores imputados con la media usando fillna():\")\n",
    "print(df_ratings.head())\n",
    "\n",
    "median_value = df_ratings['Book-Rating'].median()\n",
    "df_ratings['Book-Rating'] = df_ratings['Book-Rating'].fillna(median_value)\n",
    "print(\"Valores imputados con la mediana usando fillna():\")\n",
    "print(df_ratings.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• En ”ratings data.csv genere una nueva variable que represente el promedio de rating para cada ISBN distinto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  User-ID        ISBN  Book-Rating  MeanRating  avg_rating\n",
      "0           0   276725  034545104X          0.0    2.933333    2.933333\n",
      "1           1   276726  0155061224          5.0    2.500000    2.500000\n",
      "2           2   276727  0446520802          0.0    4.060345    4.060345\n",
      "3           3   276729  052165615X          3.0    3.000000    3.000000\n",
      "4           4   276729  0521795028          6.0    6.000000    6.000000\n"
     ]
    }
   ],
   "source": [
    "df_ratings['avg_rating'] = df_ratings.groupby('ISBN')['Book-Rating'].transform('mean')\n",
    "\n",
    "print(df_ratings.head())\n",
    "\n",
    "df_ratings.to_csv('ratings_data_with_avg_rating.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Utilizando la columna ISBN de cada base de datos consolídelas en una sola base de datos con todos los atributos de ”books data.csv”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidated = pd.merge(df_books, df_ratings, on='ISBN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Exporte la base de datos consolidada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidated.to_csv('consolidated_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
